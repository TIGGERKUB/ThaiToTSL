{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SignLanguage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Y3DmS-pl4ulnOoRc9m_nEN80i83ulv08",
      "authorship_tag": "ABX9TyPLoCZabdBOSdjWFMo+bxRm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TIGGERKUB/ThaiToTSL/blob/main/SignLanguage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GckW29f7jk_"
      },
      "source": [
        "import numpy as np\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, LSTM, Dense,Embedding\n",
        "from keras.utils import *\n",
        "from keras.initializers import *\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from attacut import tokenize, Tokenizer\n",
        "import tensorflow as tf\n",
        "import time, random\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBN3gkU2ilS_"
      },
      "source": [
        "from pythainlp.tokenize import word_tokenize\r\n",
        "from gensim.models import KeyedVectors\r\n",
        "from pythainlp import word_vector\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "from sklearn.manifold import TSNE\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.font_manager as fm\r\n",
        "\r\n",
        "import dill as pickle\r\n",
        "import pandas as pd\r\n",
        "model_path = 'thwiki_data/models/'\r\n",
        "model = word_vector.get_model()\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVnAPp-G-ABg"
      },
      "source": [
        "#Dimensionality\r\n",
        "dimensionality = 256\r\n",
        "#The batch size and number of epochs\r\n",
        "batch_size = 256\r\n",
        "epochs = 100\r\n",
        "EMBEDDING_SIZE = 100"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ7lXT_Tm1XT"
      },
      "source": [
        "#create dataframe\r\n",
        "thai2dict = {}\r\n",
        "for word in model.index2word:\r\n",
        "    thai2dict[word] = model[word]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dv2KLeig9027"
      },
      "source": [
        "def read_data(filename):\n",
        "  df = pd.read_excel(filename)\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eztDc4kV-wxf"
      },
      "source": [
        "path = \"/content/drive/MyDrive/Colab Notebooks/tsl/train_data.xlsx\"\n",
        "df = read_data(path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dot5nVZmyzsg"
      },
      "source": [
        "pairs = list(zip(df['th tokenized'],df['tsl tokenized']))\n",
        "random.shuffle(pairs)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3EH4soPcE6m"
      },
      "source": [
        "input_docs = []\n",
        "target_docs = []\n",
        "input_tokens = set()\n",
        "target_tokens = set()\n",
        "for ele in pairs:\n",
        "  input_doc, target_doc = ele[0], ele[1]\n",
        "  # Appending each input sentence to input_docs\n",
        "  input_docs.append(input_doc)\n",
        "  # Redefine target_doc below and append it to target_docs\n",
        "  target_doc = '<START> ' + target_doc + ' <END>'\n",
        "  target_docs.append(target_doc)\n",
        "  # Now we split up each sentence into words and add each unique word to our vocabulary set\n",
        "  for token in input_doc.split():\n",
        "    if token not in input_tokens:\n",
        "      input_tokens.add(token)\n",
        "  for token in target_doc.split():\n",
        "    if token not in target_tokens:\n",
        "      target_tokens.add(token)\n",
        "input_tokens = sorted(list(input_tokens))\n",
        "target_tokens = sorted(list(target_tokens))\n",
        "num_encoder_tokens = len(input_tokens)\n",
        "num_decoder_tokens = len(target_tokens)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyr9FMXN6DUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de254a1c-cc75-42ee-dcaf-f6a334a16f06"
      },
      "source": [
        "print('Number of samples:', len(input_docs))\n",
        "print('Number of target samples:', len(target_docs))\n",
        "print('Number of unique input tokens:', num_encoder_tokens)\n",
        "print('Number of unique output tokens:', num_decoder_tokens)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 99\n",
            "Number of target samples: 99\n",
            "Number of unique input tokens: 216\n",
            "Number of unique output tokens: 214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzsi2on0dT8r",
        "outputId": "a107a650-5af0-4a95-bc03-490a9d49cb47"
      },
      "source": [
        "print(input_docs[50])\r\n",
        "print(target_docs[50])\r\n",
        "print(input_tokens)\r\n",
        "print(target_tokens)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ฉัน อ่าน บทวิจารณ์ ก่อน ซื้อ\n",
            "<START> บทวิจารณ์ ฉัน อ่าน ก่อน ซื้อ <END>\n",
            "['กระดาษ', 'กระต่าย', 'กรุงเทพ', 'กรุงโตเกียว', 'กวาง', 'กับ', 'การตลาด', 'การบ้าน', 'การพักผ่อน', 'กำลัง', 'กิน', 'ก่อน', 'ก๋วยเตี๋ยว', 'ขน', 'ขนม', 'ของ', 'ขับ', 'ข้อมูล', 'ข้าว', 'คน', 'คนขาย', 'คนแปลกหน้า', 'ครัว', 'ความ', 'ความเห็น', 'คำถาม', 'คิดถึง', 'คุณครู', 'งานสัมมนา', 'ง่วง', 'จรวด', 'จระเข้', 'จอง', 'จอห์น', 'จะ', 'จับ', 'จับมือ', 'จาก', 'จาน', 'ฉลาด', 'ฉัน', 'ชอบ', 'ชาย', 'ชาวนา', 'ช่วย', 'ซื้อ', 'ญี่ปุ่น', 'ดอกไม้', 'ดี', 'ดื่ม', 'ด้านลบ', 'ตรงเวลา', 'ตอนกลางคืน', 'ตอบ', 'ตาม', 'ตำรวจ', 'ติดต่อ', 'ตุ๊กตา', 'ต้องการ', 'ถูก', 'ทรมาน', 'ทะเลสาบ', 'ทันที', 'ทั้งวัน', 'ทั้งหมด', 'ทางเทคนิค', 'ทำ', 'ทำความสะอาด', 'ทำงาน', 'ทำให้', 'ทิ้ง', 'ที่', 'ท่องเที่ยว', 'นก', 'นม', 'นอน', 'นา', 'นี้', 'น่ารัก', 'น้องสาว', 'น้ำ', 'บทวิจารณ์', 'บน', 'บันได', 'บุหรี่', 'บ้าน', 'ประวัติศาสตร์', 'ปลา', 'ปล่อย', 'ผลิตภัณฑ์', 'ผิดหวัง', 'ผู้ร้าย', 'ผู้หญิง', 'ฝ่ายสนับสนุน', 'พบ', 'พลาด', 'พวกเขา', 'พี่', 'พี่ชาย', 'พื้น', 'พเนจร', 'ฟัง', 'ฟาง', 'ภาษาจีน', 'มาก', 'มากมาย', 'มาถึง', 'มี', 'รถ', 'รอ', 'รัก', 'ราคา', 'ราคาแพง', 'ริมทะเล', 'รู้สึก', 'รู้สึกว่า', 'ร้านค้า', 'ลง', 'ลูกเป็ด', 'วางขาย', 'วิ่ง', 'วิ่งหนี', 'สถานีรถไฟ', 'สบู่', 'สวน', 'สวย', 'สอง', 'สั่ง', 'สินค้า', 'สีขาว', 'สีน้ำตาล', 'สุ่ม', 'สูบ', 'สู่', 'หนอน', 'หนัก', 'หนัง', 'หนังสือ', 'หน้า', 'หมา', 'หมาป่า', 'หมูน้อย', 'หลับ', 'หลาย', 'หิว', 'ห้อง', 'ห้องนอน', 'ห้องน้ำ', 'ห้องพัก', 'ห้างสรรพสินค้า', 'ห้าม', 'อยากได้', 'อยู่', 'อย่างบรรจง', 'อย่างมาก', 'อย่างรวดเร็ว', 'อวกาศ', 'อาหาร', 'อ่าน', 'เกี่ยวกับ', 'เก่า', 'เขา', 'เขียน', 'เข้า', 'เข้าร่วม', 'เงิน', 'เจมส์', 'เจอ', 'เจ็บป่วย', 'เจ้าเล่ห์', 'เดิน', 'เด็ก', 'เธอ', 'เนื้อหา', 'เบ่งบาน', 'เพลง', 'เยอะแยะ', 'เรียก', 'เรื่อง', 'เลือก', 'เล็ก', 'เล่ม', 'เวลา', 'เสนอ', 'เสมอ', 'เสียใจ', 'เสือ', 'เห็น', 'เอาชนะ', 'แก้ว', 'แต่', 'แท็กซี่', 'แนวหาด', 'แผน', 'แพง', 'แมว', 'แม่', 'แย่', 'แล็ปท็อป', 'โง่', 'โทรหา', 'โอน', 'ใคร', 'ใจดี', 'ใช้', 'ใช้งาน', 'ใน', 'ใหญ่', 'ใหม่', 'ให้', 'ไก่', 'ได้', 'ได้รับ', 'ไป', 'ไม่', 'ไล่']\n",
            "['<END>', '<START>', 'กระดาษ', 'กระต่าย', 'กรุงเทพ', 'กรุงโตเกียว', 'กวาง', 'กับ', 'การตลาด', 'การบ้าน', 'การพักผ่อน', 'กำลัง', 'กิน', 'ก่อน', 'ก๋วยเตี๋ยว', 'ขน', 'ขนม', 'ของ', 'ขับ', 'ข้อมูล', 'ข้าว', 'คน', 'คนขาย', 'คนแปลกหน้า', 'ครัว', 'ความเจ็บป่วย', 'ความเห็น', 'คำถาม', 'คิดถึง', 'คุณครู', 'งานสัมมนา', 'ง่วง', 'จรวด', 'จระเข้', 'จอง', 'จอห์น', 'จับ', 'จับมือ', 'จาก', 'จาน', 'ฉลาด', 'ฉัน', 'ชอบ', 'ชาย', 'ชาวนา', 'ช่วย', 'ซื้อ', 'ญี่ปุ่น', 'ดอกไม้', 'ดี', 'ดื่ม', 'ด้านลบ', 'ตรงเวลา', 'ตอนกลางคืน', 'ตอบ', 'ตาม', 'ตำรวจ', 'ติดต่อ', 'ตุ๊กตา', 'ต้องการ', 'ถูก', 'ทรมาณ', 'ทะเลสาบ', 'ทันที', 'ทั้ง', 'ทั้งหมด', 'ทางเทคนิค', 'ทำ', 'ทำความสะอาด', 'ทำงาน', 'ทิ้ง', 'ที่', 'ท่องเที่ยว', 'นก', 'นม', 'นอน', 'นา', 'นี้', 'น่ารัก', 'น้องสาว', 'น้ำ', 'บทวิจารณ์', 'บน', 'บันได', 'บุหรี่', 'บ้าน', 'ประวัติศาสตร์', 'ปลา', 'ปล่อย', 'ผลิตภัณฑ์', 'ผิดหวัง', 'ผู้ร้าย', 'ผู้หญิง', 'ฝ่ายสนับสนุน', 'พบ', 'พลาด', 'พวกเขา', 'พี่', 'พี่ชาย', 'พื้น', 'พเนจร', 'ฟัง', 'ฟาง', 'ภาษาจีน', 'มาก', 'มากมาย', 'มาถึง', 'มี', 'รถ', 'รอ', 'รัก', 'ราคา', 'ราคาแพง', 'ริมทะเล', 'รู้สึก', 'ร้านค้า', 'ลง', 'ลูกเป็ด', 'วัน', 'วางขาย', 'วิ่ง', 'วิ่งหนี', 'ว่า', 'สถานีรถไฟ', 'สบู่', 'สวน', 'สวย', 'สอง', 'สั่ง', 'สินค้า', 'สีขาว', 'สีน้ำตาล', 'สุ่ม', 'สูบ', 'สู่', 'หนอน', 'หนัก', 'หนัง', 'หนังสือ', 'หน้า', 'หมา', 'หมาป่า', 'หมูน้อย', 'หลับ', 'หลาย', 'หิว', 'ห้อง', 'ห้องนอน', 'ห้องน้ำ', 'ห้องพัก', 'ห้างสรรพสินค้า', 'ห้าม', 'อยากได้', 'อยู่', 'อย่างบรรจง', 'อย่างมาก', 'อย่างรวดเร็ว', 'อวกาศ', 'อาหาร', 'อ่าน', 'เกี่ยวกับ', 'เก่า', 'เขา', 'เขียน', 'เข้า', 'เข้าร่วม', 'เงิน', 'เจมส์', 'เจอ', 'เจ้าเล่ห์', 'เดิน', 'เด็ก', 'เธอ', 'เนื้อหา', 'เบ่งบาน', 'เพลง', 'เรียก', 'เรื่อง', 'เลือก', 'เล็ก', 'เล่ม', 'เวลา', 'เสนอ', 'เสมอ', 'เสียใจ', 'เสือ', 'เห็น', 'เอาชนะ', 'แก้ว', 'แท็กซี่', 'แนวหาด', 'แผน', 'แพง', 'แมว', 'แม่', 'แย่', 'แล็ปท็อป', 'โง่', 'โทรหา', 'โอน', 'ใคร', 'ใจดี', 'ใช้', 'ใช้งาน', 'ใน', 'ใหญ่', 'ใหม่', 'ให้', 'ไก่', 'ได้', 'ได้รับ', 'ไป', 'ไม่', 'ไล่']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hX_7vKOg6ufH"
      },
      "source": [
        "input_features_dict = dict([(token, i) for i, token in enumerate(input_tokens)])\n",
        "target_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n",
        "reverse_input_features_dict = dict((i, token) for token, i in input_features_dict.items())\n",
        "reverse_target_features_dict = dict((i, token) for token, i in target_features_dict.items())"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss9QKYnTxI8a"
      },
      "source": [
        "#Maximum length of sentences in input and target documents\r\n",
        "max_encoder_seq_length = max([len(input_doc.split()) for input_doc in input_docs])\r\n",
        "max_decoder_seq_length = max([len(target_doc.split()) for target_doc in target_docs])"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Cqpuktx7-RL"
      },
      "source": [
        "encoder_input_data = np.zeros((len(input_docs), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
        "decoder_input_data = np.zeros((len(input_docs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "decoder_target_data = np.zeros((len(input_docs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
        "\n",
        "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
        "  for timestep, token in enumerate(input_doc.split()):\n",
        "    #Assign 1. for the current line, timestep, & word in encoder_input_data\n",
        "    encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
        "  for timestep, token in enumerate(target_doc.split()):\n",
        "    decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
        "    if timestep > 0:\n",
        "      decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBrRtFXV9gjE"
      },
      "source": [
        "#Encoder\n",
        "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
        "encoder_lstm = LSTM(dimensionality, return_state=True)\n",
        "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [state_hidden, state_cell]\n",
        "#Decoder\n",
        "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
        "decoder_lstm = LSTM(dimensionality, return_sequences=True, return_state=True)\n",
        "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5idCe08C9n7F"
      },
      "source": [
        "#Model\n",
        "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "#Compiling\n",
        "training_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'], sample_weight_mode='temporal')\n",
        "#Training\n",
        "training_model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size = batch_size, epochs = epochs, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO5qdrvGB5UT"
      },
      "source": [
        "training_model.save('training_model.h5')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E07s2WvE-9LK"
      },
      "source": [
        "training_model = load_model('training_model.h5')\n",
        "encoder_inputs = training_model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = Model(encoder_inputs, encoder_states)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMQx90tI_Hw9"
      },
      "source": [
        "latent_dim = 256\n",
        "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
        "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_FTb870_JQw"
      },
      "source": [
        "decoder_outputs, state_hidden, state_cell = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "decoder_states = [state_hidden, state_cell]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctK0zpG1CM_6"
      },
      "source": [
        "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_p_yMd0-bY3"
      },
      "source": [
        "def decode_response(test_input):\n",
        "    #Getting the output states to pass into the decoder\n",
        "    states_value = encoder_model.predict(test_input)\n",
        "    #Generating empty target sequence of length 1\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    #Setting the first token of target sequence with the start token\n",
        "    target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
        "    \n",
        "    #A variable to store our response word by word\n",
        "    decoded_sentence = ''\n",
        "    \n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "      #Predicting output tokens with probabilities and states\n",
        "      output_tokens, hidden_state, cell_state = decoder_model.predict([target_seq] + states_value)\n",
        "      #Choosing the one with highest probability\n",
        "      sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "      sampled_token = reverse_target_features_dict[sampled_token_index]\n",
        "      decoded_sentence += \" \" + sampled_token#Stop if hit max length or found the stop token\n",
        "      if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
        "        stop_condition = True\n",
        "      #Update the target sequence\n",
        "      target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "      target_seq[0, 0, sampled_token_index] = 1.\n",
        "      #Update states\n",
        "      states_value = [hidden_state, cell_state]\n",
        "    return decoded_sentence"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-QQHio--ekf"
      },
      "source": [
        "class Translator:\n",
        "  exit_commands = (\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\")\n",
        "  \n",
        "  #Method to start the translator\n",
        "  def start(self):\n",
        "    user_response = input(\"Give in an sentence. :) \\n\")\n",
        "    self.translate(user_response)\n",
        "  \n",
        "  #Method to handle the conversation\n",
        "  def translate(self, reply):\n",
        "    while not self.make_exit(reply):\n",
        "      reply = input(self.generate_response(reply)+\"\\n\")\n",
        "  #Method to convert user input into a matrix\n",
        "  def string_to_matrix(self, user_input):\n",
        "    atta = Tokenizer(model=\"attacut-sc\")\n",
        "    words = atta.tokenize(user_input)\n",
        "    tokens = words\n",
        "    user_input_matrix = np.zeros((1, max_encoder_seq_length, num_encoder_tokens),dtype='float32')\n",
        "    for timestep, token in enumerate(tokens):\n",
        "      if token in input_features_dict:\n",
        "        user_input_matrix[0, timestep, input_features_dict[token]] = 1.\n",
        "    return user_input_matrix\n",
        "  \n",
        "  #Method that will create a response using seq2seq model we built\n",
        "  def generate_response(self, user_input):\n",
        "    input_matrix = self.string_to_matrix(user_input)\n",
        "    chatbot_response = decode_response(input_matrix)\n",
        "    #Remove <START> and <END> tokens from chatbot_response\n",
        "    chatbot_response = chatbot_response.replace(\"<START>\",'')\n",
        "    chatbot_response = chatbot_response.replace(\"<END>\",'')\n",
        "    return chatbot_response\n",
        "  \n",
        "  #Method to check for exit commands\n",
        "  def make_exit(self, reply):\n",
        "    for exit_command in self.exit_commands:\n",
        "      if exit_command in reply:\n",
        "        print(\"Ok, have a great day!\")\n",
        "        return True\n",
        "    return False\n",
        "  \n",
        "translator = Translator()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "Pg8iqSfAm88-",
        "outputId": "081d77f2-49e6-4893-bae8-0af2e8367969"
      },
      "source": [
        "translator.start()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    565\u001b[0m         \"\"\"\n\u001b[0;32m--> 566\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-7a63b09971ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-3a670b55749a>\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m#Method to start the translator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0muser_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Give in an sentence. :) \\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}